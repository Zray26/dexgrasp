<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>DexGrasp-Diffusion: Diffusion-based Unified Functional Grasp Synthesis Pipeline for Multi-Dexterous Robotic Hands </title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script> -->
  <!-- <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script> -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="icon" href="./static/images/favicon.svg"> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>


  <style>
    html {
      height: 100%;
      background-color: #fafafa;
    }

    body {
      height: 100%;
      display: flex;
      flex-direction: column;
      background-color: #fafafa;
    }

    #app {
      height: 100%;
      display: flex;
      flex-direction: column;
    }

    hr {
      background-color: #f1f1f1;
    }

    .table th {
      padding: 0.2em 0.2em 0 0.2em;
      width: 50%;
    }

    .table td {
      padding: 0.25em;
      width: 50%;
    }

    .content-block {
      padding: 0 6px;
    }

    .title {
      font-size: 32px;
      padding-top: 32px;
    }

    .publisher {
      margin-bottom: 1rem;
    }

    .sub-title {
      font-size: 26px;
      padding-bottom: 16px;
    }

    .subsub-title {
      font-size: 20px;
      padding-bottom: 8px;
    }

    .author {
      font-size: 16px;
    }

    .task {
      padding-bottom: 12px;
    }

    @media screen and (min-width: 880px) {
      .is-840px {
        flex: none;
        width: 840px;
      }
    }
    @media screen and (max-width: 879px) {
      .is-100per {
        flex: none;
        width: 100%;
      }
    }
  </style>




</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <!-- <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div> -->
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">DexGrasp-Diffusion: Diffusion-based Unified Functional Grasp Synthesis Pipeline for Multi-Dexterous Robotic Hands </h1>
          <div class="is-size-5 publication-authors">
         
            <span class="author-block">
              Zhengshen Zhang<sup>1</sup>,   <span class="author-block">
              <a href="https://zray26.github.io">Lei Zhou</a><sup>1</sup>,</span>
            <span class="author-block">
              Chenchen Liu<sup>1</sup>,</span>
            </span>
            <span class="author-block">
              Zhiyang Liu<sup>1</sup>,
            </span>
            <span class="author-block">
              Chengran Yuan<sup>1</sup>,
            </span>
            <span class="author-block">
              Sheng Guo<sup>1</sup>,
            </span>
            <span class="author-block">
              Ruiteng Zhao<sup>1</sup>,
            </span>
            <span class="author-block">
              Marcelo H. Ang Jr.<sup>1</sup>,
            </span>
            <span class="author-block">
              Francis EH Tay<sup>1</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>National University of Singapore</span>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            The versatility and adaptability of human grasping catalyze advancing dexterous robotic manipulation. While significant strides have been made in dexterous grasp generation, current research endeavors pivot towards optimizing object manipulation while ensuring functional integrity, emphasizing the synthesis of functional grasps following desired affordance instructions. This paper addresses the challenge of synthesizing functional grasps tailored to diverse dexterous robotic hands by proposing DexGrasp-Diffusion, an end-to-end modularized diffusion-based pipeline. DexGrasp-Diffusion integrates MultiHandDiffuser, a novel unified data-driven diffusion model for multi-dexterous hands grasp estimation, with DexDiscriminator, which employs a Physics Discriminator and a Functional Discriminator with open-vocabulary setting to filter physically plausible functional grasps based on object affordances. The experimental evaluation conducted on the MultiDex dataset provides substantiating evidence supporting the superior performance of MultiHandDiffuser over the baseline model in terms of success rate, grasp diversity, and collision depth. Moreover, we demonstrate the capacity of DexGrasp-Diffusion to reliably generate functional grasps for household objects aligned with specific affordance instructions.
          </p>
        
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->


    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <!-- <iframe src="https://youtu.be/9w-tQ6pxft0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe> -->
          <video src="./static/videos/supplementary_video.mp4" autoplay muted controls></video>
          <!-- <iframe width="420" height="315" allow="autoplay ; encrypted-media" src="https://www.youtube.com/embed/9w-tQ6pxft0" ></iframe> -->
        </div>
      </div>
    </div>
  </div>

<section class="pipeline">
  <div class="container is-max-desktop">
    <div class="hero-body is-centered has-text-centered">
      <h2 class="title is-3">Pipeline</h2>
      <!-- <img id="teaser" width=100%> -->
      <img src="./static/images/pipeline.png"  width=100%>
      <!-- </img> -->
      <h2 class="subtitle has-text-centered">
      </h2>

      <h2 class="subtitle has-text-centered">
        <b>Training: </b> Given a ground truth hand pose h<sub>0</sub> in the dataset, Gaussian noise &#949 is gradually added to h<sub>0</sub> to obtain a series of intermediate hand poses h<sub>t</sub>. Conditioned on various conditions, including time step, object point cloud, finger padding mask, hand class, and hand point cloud, the diffusion model predicts noise added to the h<sub>0</sub>.
      
        <b>Testing:</b> Given a noisy hand pose sampled from a standard multivariate Gaussian distribution h<sub>T</sub> &#126 <i>N(0,I)</i>  as the initial state, it corrects h<sub>t</sub> to less noisy pose h<sub>t-1</sub> at each time step. Subsequently, two discriminators are applied to filter physically feasible and functional grasps.
 
      </h2>
    </div>
  </div>
</section>

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Denosing Process</h2>
        <div class="publication-video">
          <!-- <iframe src="https://youtu.be/9w-tQ6pxft0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe> -->
          <video src="./static/videos/Denoising.mp4" muted autoplay loop></video>
          <!-- <iframe width="420" height="315" allow="autoplay ; encrypted-media" src="https://www.youtube.com/embed/9w-tQ6pxft0" ></iframe> -->
        </div>
        <h2 class="subtitle has-text-centered">
          Starting from random initial hand poses, our diffusion model iteratively de-noise hand poses for T steps.
        </h2>
      </div>
    </div>
  </div>


<!-- <div class="columns is-centered has-text-centered">
  <div style="background-color: white; padding: 15px;">
    <h3 style="border-bottom: 1px solid; margin: 0 0 8px 0; font-size: 18px; font-weight: 600;">Tok k Grasp Poses</h3>
  <img src='./static/images/ICRA2024_results.drawio.png' width=80%>
  </div>
</div> -->


<!-- 
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre>
  </div>
</section> -->

<!-- <script type="text/javascript">
  $(function (){
  $(".secdiv").load("./static/images/contactdb+apple+sample-0.html");
 });
 </script>

<include src="./static/images/contactdb+apple+sample-0.html"></include> -->

<!-- <head>
  <link rel="import" href="./static/images/contactdb+apple+sample-0.html">
</head> -->

<!-- 
<head> 
  <title>Embedded Web Page</title> 
</head> 
<body> 
 
<h2>Displaying Another Web Page</h2> 
 
<iframe src="./static/html/allegro/contactdb+apple+sample-5_step-1000.html" width="400" height="400" allow="fullscreen aligned"></iframe> 
<iframe src="./static/html/allegro/contactdb+camera+sample-11_step-1000.html" width="400" height="400" title="Embedded Page"></iframe> 
<iframe src="./static/html/allegro/contactdb+hammer+sample-17_step-1000.html" width="400" height="400" title="Embedded Page"></iframe> 
<iframe src="./static/html/allegro/ycb+potted_meat_can+sample-9_step-1000.html" width="400" height="400" title="Embedded Page"></iframe> 
<iframe src="./static/html/allegro/ycb+tomato_soup_can+sample-6_step-1000.html" width="400" height="400" title="Embedded Page"></iframe> 
</body>  -->

<!-- <head> 
  <script src="jquery.js"></script> 
  <script> 
  $(function(){
    $("#includedContent").load("./static/images/contactdb+apple+sample-0.html"); 
  });
  </script> 
</head>  -->

<!-- 
<div class="task">
  <div class="columns is-centered" style="position: relative;">
    <div style="position: absolute; left: 3%; top: 3%;">
      <span style="font-size: 0.8em;">Object </span>
      <div class="select is-small">
        <select id="objectSelector">
          <option>allegro</option>
          <option>barrett</option>
          <option>ezgripper</option>
          <option>robotiq_3finger</option>
          <option>shadowhand</option>
        </select>
      </div>
      &nbsp;&nbsp;&nbsp;
      <span style="font-size: 0.8em;">Sample </span>
      <div class="select is-small">
        <select id="sampleSelector">
          <option>grasp_0</option>
          <option>grasp_1</option>
          <option>grasp_2</option>
          <option>grasp_3</option>
        </select>
      </div>
    </div>
    <div id="grasp_loading" style="position: absolute; left: 50%; top: 45%;"></div>
    <canvas id="webgl_grasp" style="height: 50%; width: 50%;"></canvas>
  </div>
  <p style="margin: 0 1.5em; font-size: 0.8em; text-align:justify;">Note: Click the select dropdown to select a object and a pre-sampled grasp for result visualization. Drag to move your view around.</p>
</div> -->



<section class="functional">
  <div class="container is-max-desktop">
    <div class="hero-body is-centered has-text-centered">
      <h2 class="title is-3">Functional Discriminator</h2>
      <!-- <img id="teaser" width=100%> -->
      <img src="./static/images/functional.png"  width=100%>
      <!-- </img> -->
      <h2 class="subtitle has-text-centered">
        Given an open-vocabulary affordance label, the functional discriminator implements point cloud segmentation. Green points represent region where the robot can grasp the object without impeding its intended functionality.
      </h2>
    </div>
  </div>
</section>
<div w3-include-html="./static/html/allegro/contactdb+apple+sample-5_step-1000.html"></div>
<ui:include src="./static/html/allegro/contactdb+apple+sample-5_step-1000.html" />


<footer class="footer">
  <!-- <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div> -->
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This webpage template was inspired from <a
              href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>





</body>



         



<script type="module">

  import * as THREE from 'three'
  import { OrbitControls } from 'three/addons/controls/OrbitControls.js'
  import {GLTFLoader} from 'three/addons/loaders/GLTFLoader.js'

  // grasp generation for 3D object
  let canvas2 = document.querySelector('#webgl_grasp')
  let scene2 = new THREE.Scene()
  let assetLoader2 = new GLTFLoader()
  let model2

  let camera2 = new THREE.PerspectiveCamera(45, 1.618 / 1.0, 0.1, 100)
  camera2.position.set(0.25, 0.2, -0.25)
  let grid2 = new THREE.GridHelper(30, 30)
  scene2.add(camera2)
  scene2.add(grid2)
  for (let ax = 0; ax < 3; ax++) {
    for (let i = 0; i <= 1; i++) {
      let spotLight = new THREE.SpotLight(0xAAAAAA)
      spotLight.position.set(
        ax == 0 ? 50 * (i * 2 - 1): 0,
        ax == 1 ? 50 * (i * 2 - 1): 0,
        ax == 2 ? 50 * (i * 2 - 1): 0,
      )
      scene2.add(spotLight)
    }
  }

  let controls2 = new OrbitControls(camera2, canvas2)
  controls2.enableZoom = true
  // controls2.enableDamping = true
  controls2.object.position.set(camera2.position.x, camera2.position.y, camera2.position.z)
  controls2.target = new THREE.Vector3(0, 0, 0)
  controls2.update()

  let renderer2 = new THREE.WebGLRenderer({
      canvas: canvas2,
      alpha: true,
  })
  renderer2.setPixelRatio(Math.min(window.devicePixelRatio, 2))
  renderer2.outputEncoding = THREE.sRGBEncoding
  renderer2.setAnimationLoop(() => {
    renderer2.render(scene2, camera2)
  });

  const objSel = document.querySelector('#objectSelector')
  const samSel = document.querySelector('#sampleSelector')
  objSel.value = 'allegro'
  samSel.value = 'grasp_0'

  function load_model2(e) {
    if (objSel.value == '' || samSel.value == '') {
      return
    }
    scene2.remove(model2)
    document.querySelector('#grasp_loading').innerHTML = `<img src="./static/icons/loading.svg" width="48" height="48">`
    // let assetUrl = new URL(`./assets/grasp_generation_color/${objSel.value}/${samSel.value}.glb`, import.meta.url)
    // let assetUrl = new URL(`./static/html/${objSel.value}/${samSel.value}.html`, import.meta.url)
    let assetUrl = new URL(`./static/html/allegro/grasp_0.html`, import.meta.url)
    
    // let assetUrl = new URL(`./static/html/allegro/contactdb+apple+sample-5_step-1000.html`, import.meta.url)
    assetLoader2.load(assetUrl.href, gltf => {
      model2 = gltf.scene
      scene2.add(model2)
      document.querySelector('#grasp_loading').innerHTML = ''
    }, undefined, (error) => {console.error(error)})
  }

  objSel.addEventListener('change', (e) => {samSel.value = ''})
  samSel.addEventListener('change', load_model2)
  load_model2()

  // resize renderers
  function resizeRenderers() {
    let content_width = document.querySelector('#results').offsetWidth
    renderer1.setSize(content_width, content_width / 1.618)
    renderer2.setSize(content_width, content_width / 1.618)
  }
  window.addEventListener('resize', () => {
    resizeRenderers()
  })
  resizeRenderers()
</script>




</html>
